# CUDA C 权威编程指南

## 目录

[第 1 章 基于 CUDA 的异构并行计算](#第-1-章-基于-cuda-的异构并行计算)  
[第 2 章 CUDA 编程模型](#第-2-章-cuda编程模型)  
[第 3 章 CUDA 执行模型](#第-3-章-cuda执行模型)  
[第 4 章 全局内存](#第-4-章-全局内存)  
[第 5 章 共享内存和常量内存](#第-5-章-共享内存和常量内存)  
[第 6 章 流和并发](#第-6-章-流和并发)  
[第 7 章 调整指令级原语](#第-7-章-调整指令级原语)  
[第 8 章 GPU 加速库和 OpenACC](#第-8-章-gpu加速库和openacc)  
[第 9 章 多 GPU 编程](#第-9-章-多gpu编程)  
[第 10 章 程序实现的注意事项](#第-10-章-程序实现的注意事项)

## 第 1 章 基于 CUDA 的异构并行计算

CPU 有处理复杂逻辑和指令级并行性的能力；GPU 中有大量可编程的核心，可以支持大规模多线程运算，而且相比 CPU 有较大的峰值带宽。

- CPU：较小的数据规模、复杂的控制逻辑、很少的并行性；
- GPU：较大规模的待处理数据、大量的数据并行性。

构建 GPU 应用程序的方法是使用 CUDA 工具包，包括编译器、数学库，以及调试和优化应用程序性能的工具等。

## 第 2 章 CUDA 编程模型

一个典型的 CUDA 程序实现流程遵循以下模式：

1. 为 GPU 分配内存；
2. 将数据从 CPU 内存拷贝到 GPU 内存；
3. 调用核函数操作 GPU 内存中的数据；
4. 将数据从 GPU 内存拷贝到 CPU 内存；
5. 释放 GPU 内存。

### 内存管理

| 标准的 C 函数 | CUDA C 函数 |
| ------------- | ----------- |
| malloc        | cudaMalloc  |
| memcpy        | cudaMemcpy  |
| memset        | cudaMemset  |
| free          | cudaFree    |

函数原型：

```c
// cudaMalloc
cudaError_t cudaMalloc(void **devPtr, size_t size);
// cudaMemcpy
cudaError_t cudaMemcpy(void *dst, const void *src, size_t count, cudaMemcpyKind kind);
/*
复制方向由kind指定：
    cudaMemcpyHostToHost
    cudaMemcpyHostToDevice
    cudaMemcpyDeviceToHost
    cudaMemcpyDeviceToDevice
    cudaMemcpyDefault
*/
// cudaMemset
cudaError_t cudaMemset(void *devPtr, int value, size_t count);
// cudaFree
cudaError_t cudaFree(void *devPtr);
```

### 核函数

函数类型限定符

| 限定符       | 执行         | 调用                  | 备注                                                               |
| ------------ | ------------ | --------------------- | ------------------------------------------------------------------ |
| `__global__` | 在设备端执行 | 可从主机端/设备端调用 | 必须有一个 void 返回类型                                           |
| `__device__` | 在设备端执行 | 仅能从设备端调用      | **device**和**host**可以同时使用，函数会在主机和设备端都进行编译。 |
| `__host__`   | 在主机端执行 | 仅能从主机端调用      | 可以省略                                                           |

用`__global__`修饰符定义核函数：

```c
__global__ void kernelFunction(int *array) { ... };
```

核函数通过特殊的语法调用，称为执行配置（execution configuration），指定网格（grid）和块（block）的尺寸：

```cuda
kernelFunction<<<blocks, threads>>>(param);
```

核函数的限制：

- 只能访问设备内存；
- 必须具有 void 返回类型；
- 不支持可变数量的参数；
- 不支持静态变量；
- 显示异步行为。

验证核函数代码时，除了使用调试工具外，还可以：

1. 在核函数中使用`printf`函数；
2. 将执行参数设置为`<<<1, 1>>>`，强制用一个块和一个线程执行核函数，模拟串行执行。

### 错误处理

将`cudaError_t`错误代码转换为人类可读的字符串描述：

```c
const char* cudaGetErrorString(cudaError_t error);
```

可以定义宏函数检查错误：

```c
#define CHECK(call)\
{\
  const cudaError_t error=call;\
  if(error!=cudaSuccess)\
  {\
      printf("ERROR: %s:%d,",__FILE__,__LINE__);\
      printf("code:%d,reason:%s\n",error,cudaGetErrorString(error));\
      exit(1);\
  }\
}
```

## 第 3 章 CUDA 执行模型

### GPU 架构概述

GPU 是围绕着流式多处理器（SM）的可扩展阵列搭建的，SM 的关键组件如下：

- CUDA 核心
- 共享内存/一级缓存
- 寄存器文件
- 加载/存储单元
- 特殊功能单元
- 线程束调度器

![sm](img/SM.png)

### 线程束和线程块

CUDA 采用单指令多线程（SIMT）架构来管理和执行线程，每 32 个线程为一组，被称为线程束（warp）。一个 SM 上在某一个时刻，有 32 个线程在执行同一条指令（有些可以不执行，但是只能空闲，不能执行其他指令）。当一个核函数的网格（grid）被启动时，多个线程块（block）会被同时分配给可用的 SM 上执行。在 SM 上，同一个块内的多个线程进行线程级别并行；而同一线程内，指令利用指令级并行将单个线程处理成流水线。

_注意: 当一个 block 被分配给一个 SM 后，不能被重新分配到其他 SM 上；多个线程块可以被分配到同一个 SM 上。_

SIMT 模型具有 3 个关键特征：

1. 每个线程都有自己的指令地址计数器；
2. 每个线程都有自己的寄存器状态；
3. 每个线程可以有一个独立的执行路径。

![logic](img/logic.png)

_线程块（block）是软件概念，线程束是硬件概念。_

![wraps](img/wraps.png)

线程块被分配到某一个 SM 上以后，将分为多个线程束，每个线程束 32 个线程，依次在 SM 上执行。在块中，每个逻辑线程有唯一的编号`threadIdx`；网格中，每个逻辑线程块也有唯一的编号`blockIdx`。这些编号是三维地址`dim3`，类似于`t[z][y][x]`，对应的线性地址是：

$tid=threadIdx.x+threadIdx.y×blockDim.x+threadIdx.z×blockDim.x×blockDim.y$

### 资源分配

每个 SM 上执行的基本单位是线程束，已经分配了 SM 资源的线程束称为**已激活**，一旦被激活，这个线程束就不会离开 SM 直至执行结束。每个 SM 上有多少个线程束处于激活状态，取决于以下资源：

- 程序计数器
- 寄存器
- 共享内存

当寄存器和共享内存分配给了线程块，这个线程块处于活跃状态，所包含的线程束称为活跃线程束。活跃的线程束又分为三类：

- 选定的线程束：SM 正在执行的线程束
- 阻塞的线程束：等待执行的线程束
- 符合条件的线程束：准备要执行的线程束（执行所需的资源全部就位）

### 延迟隐藏

GPU 的延迟通常分为两种：

- 算术延迟：10~20 个时钟周期
- 内存延迟：400~800 个时钟周期

当有较多可用的线程束供其调度，这时候可以达到计算资源的完全利用，可以提高并发数，起到隐藏每个指令的延迟的效果。所以，延迟的隐藏取决于活动的线程束的数量，数量越多，隐藏的越好，但是线程束的数量又受到 SM 的可分配资源影响。所以需要寻找最优的执行配置来达到最优的延迟隐藏。

![delay](img/delay.png)

$所需线程束（下界）=延迟×吞吐量$

_吞吐量：指每分钟处理多少个指令。_

### 同步

#### 系统级同步

`cudaDeviceSynchronize()`是一个主机端显式同步函数，用于等待设备上的所有 CUDA 核函数（kernel）执行完成，并将控制权恢复给主机线程。

```c
cudaError_t cudaDeviceSynchronize(void);
```

另外还有隐式同步方法，某些函数会阻塞到设备端执行完，以实现隐式同步。比如内存拷贝函数：

```c
cudaError_t cudaMemcpy(void *dst, const void *src, size_t count, cudaMemcpyKind kind);
```

#### 块级同步

`__syncthreads()`用于实现块内同步，使同一个线程块中的每个线程都必须等待其他线程到达这个同步点。

```c
__device__ void __syncthreads(void);
```

### 并行性

![parallel](img/parallel.png)

不同设备和算法上，没有一个固定最优的执行参数，需要在几个相关的指标间寻找一个恰当的平衡来达到最佳的总体性能。

### 线程束分化

同一个线程束中的线程，需要执行不同的指令，这叫做线程束的分化。由于一个 SM 只有一个调度器，产生分化的线程只能串行执行，因此条件分支越多，并行性削弱越严重。

要线程束分化导致的性能下降，根本思路是避免同一个线程束内的线程分化。

_很多时候，编译器会优化线程束分化，但是编程时仍然需要考虑分支效率最大化。_

### 展开循环

GPU 没有分支预测能力，每一个分支都会执行，因此 cuda 程序中需要尽量减少分支。通过展开循环来减少迭代次数，增加更多的独立调度指令来提高性能，它们可以帮助隐藏指令或内存延迟。

### 动态并行

动态并行，是在核函数中调用核函数，类似于递归。利用动态并行，可以：

1. 推迟到运行时决定需要在 GPU 上创建多少个块和网格，可以动态地利用 GPU 硬件调度器和加载平衡器，并进行调整以适应数据驱动或工作负载。
2. 让复杂的核函数具有层次性。

## 第 4 章 全局内存

### CUDA 内存模型

GPU 上的可编程内存有：

- 寄存器
- 共享内存
- 本地内存
- 常量内存
- 纹理内存
- 全局内存

![mem](img/memory.png)

#### 寄存器

寄存器对于每个线程是私有的，寄存器通常保存被频繁使用的私有变量；寄存器变量的生命周期和核函数一致，从开始执行到执行结束。

寄存器是 SM 中的稀缺资源，每个线程的寄存器数量有限（Fermi63 个，Kepler255 个）；一个线程如果使用更少的寄存器，那么 SM 上并发的线程块就能越多。

如果一个线程变量太多，就会发生寄存器溢出，变量将被存储到本地内存中。nvcc 编译器使用启发式策略来最小化寄存器的使用，以避免寄存器溢出。也可以在核函数的代码中配置额外的信息来辅助编译器优化，比如：

```c
__global__ void
__lauch_bounds__(maxThreadaPerBlock,minBlocksPerMultiprocessor)
kernel(...) {
    /* kernel code */
}
/**
* maxThreadsPerBlock指出了每个线程块可以包含的最大线程数
* minBlockPerMultiprocessor是可选参数，指明了在每个SM中预期的最小的常驻线程块数量
*/
```

还可以使用 nvcc 编译器选项`-maxrregcount=32`指定核函数使用寄存器的最大数量。

#### 本地内存

核函数中符合存储在寄存器中但不能进入被核函数分配的寄存器空间中的变量将存储在本地内存中，编译器可能存放在本地内存中的变量有以下几种：

- 使用未知索引引用的本地数组
- 可能会占用大量寄存器空间的较大本地数组或者结构体
- 任何不满足核函数寄存器限定条件的变量

#### 共享内存

在核函数中使用`__share__`修饰符的内存，称为共享内存。共享内存在核函数内声明，对块内线程可见，生命周期和线程块一致。块内线程可以通过共享内存进行通信，也存在竞争问题。

SM 中的一级缓存，和共享内存共享一个片上内存，他们通过静态划分，划分彼此的容量，运行时可以通过下面语句进行设置：

```c
cudaError_t cudaFuncSetCacheConfig(const void * func,enum cudaFuncCache);
/**
* cudaFuncCachePreferNone 无参考值，默认设置
* cudaFuncCachePreferShared 48k共享内存，16k一级缓存
* cudaFuncCachePreferL1 48k一级缓存，16k共享内存
* cudaFuncCachePreferEqual 32k一级缓存，32k共享内存
*/
```

#### 常量内存

常量内存驻留在设备内存中，每个 SM 都有专用的常量内存缓存，常量内存使用`__constant__`修饰。常量内存在核函数外、全局范围内静态声明，并对同一编译单元中的所有核函数可见。常量内存初始化后不能被核函数修改，初始化函数如下：

```c
cudaError_t cudaMemcpyToSymbol(const void* symbol,const void *src,size_t count);
```

常量内存的一次读取会广播给所有线程束内的线程，因此适合不同的线程取同一地址的数据。

#### 纹理内存

纹理内存驻留在设备内存中，在每个 SM 的只读缓存中缓存，纹理内存是通过指定的缓存访问的全局内存，只读缓存包括硬件滤波的支持，它可以将浮点插入作为读取过程中的一部分来执行，纹理内存是对二维空间局部性的优化。

#### 全局内存

GPU 上最大的内存空间，延迟最高，使用最常见的内存，一般在主机端代码里定义，也可以在设备端用修饰符`__device__`定义，只要不销毁，是和应用程序同生命周期的。

#### GPU 缓存

与 CPU 缓存类似，GPU 缓存不可编程，其行为出厂是时已经设定好了。GPU 上有 4 种缓存：

1. 一级缓存
2. 二级缓存
3. 只读常量缓存
4. 只读纹理缓存

每个 SM 都有一个一级缓存，所有 SM 公用一个二级缓存。一级二级缓存的作用都是被用来存储本地内存和全局内存中的数据，也包括寄存器溢出的部分。每个 SM 有一个只读常量缓存和只读纹理缓存，它们用于设备内存中提高来自于各自内存空间内的读取性能。

#### CUDA 变量声明总结

| 修饰符         | 变量名称         | 存储器 | 作用域 | 生命周期 |
| -------------- | ---------------- | ------ | ------ | -------- |
|                | `float var`      | 寄存器 | 线程   | 线程     |
|                | `float var[100]` | 本地   | 线程   | 线程     |
| `__share__`    | `float var*`     | 共享   | 块     | 块       |
| `__device__`   | `float var*`     | 全局   | 全局   | 应用程序 |
| `__constant__` | `float var*`     | 常量   | 全局   | 应用程序 |

设备存储器的重要特征：

| 存储器 | 片上/片外 | 缓存       | 存取 | 范围            | 生命周期 |
| ------ | --------- | ---------- | ---- | --------------- | -------- |
| 寄存器 | 片上      | n/a        | R/W  | 一个线程        | 线程     |
| 本地   | 片外      | 1.0 以上有 | R/W  | 一个线程        | 线程     |
| 共享   | 片上      | n/a        | R/W  | 块内所有线程    | 块       |
| 全局   | 片外      | 1.0 以上有 | R/W  | 所有线程 + 主机 | 主机配置 |
| 常量   | 片外      | Yes        | R    | 所有线程 + 主机 | 主机配置 |
| 纹理   | 片外      | Yes        | R    | 所有线程 + 主机 | 主机配置 |

#### 静态全局内存

CPU 内存有动态分配和静态分配两种类型，动态分配在堆上进行，静态分配在栈上进行。在 CUDA 中也有类似的动态静态之分。对于静态分配的设备内存，不能用动态 copy 的方法`cudaMemcpy(&value,devData,sizeof(float));`，只能用静态传值：

```c
// 给静态设备变量赋值
cudaMemcpyToSymbol(devData,&value,sizeof(float));
// 获取静态设备变量的值
cudaMemcpyFromSymbol(&value,devData,sizeof(float));
```

下面是静态分配全局内存的例子：

```c
#include <cuda_runtime.h>
#include <stdio.h>
// __device__变量与主机变量不同，在主机看来是一个指针
__device__ float devData;
__global__ void checkGlobalVariable()
{
    printf("Device: The value of the global variable is %f\n",devData);
    devData += 2.0;
}
int main()
{
    float value=3.14f;
    // 传devData相当于传地址
    cudaMemcpyToSymbol(devData,&value,sizeof(float));
    printf("Host: copy %f to the global variable\n",value);
    checkGlobalVariable<<<1,1>>>();
    // 同上
    cudaMemcpyFromSymbol(&value,devData,sizeof(float));
    printf("Host: the value changed by the kernel to %f \n",value);
    cudaDeviceReset();
    return EXIT_SUCCESS;
}
```

需要注意：

1. 在主机端，设备变量只是一个标识符，主机代码不能直接访问设备变量；
2. 在核函数中，设备变量就是一个全局内存中的变量，可以直接访问。

### 内存管理

#### 固定内存

主机内存采用分页式管理，应用程序通过虚拟内存地址访问内存。但是从主机传输到设备上的时候，如果此时发生了页面移动，对于传输操作来说是致命的。所以在数据传输之前，CUDA 驱动会锁定页面，或者直接分配固定的主机内存，将主机源数据复制到固定内存上，然后从固定内存传输数据到设备上。直接分配固定的主机内存的方法如下：

```c
// 分配count字节的固定内存，这些内存是页面锁定的，可以直接传输到设备，提高传输带宽
cudaError_t cudaMallocHost(void ** devPtr, size_t count);
// 释放固定内存
cudaError_t cudaFreeHost(void *ptr);
```

#### 零拷贝内存

GPU 线程可以直接访问主机上的零拷贝内存。零拷贝内存是固定内存，不可分页。可以通过以下函数创建零拷贝内存：

```c
cudaError_t cudaHostAlloc(void ** pHost,size_t count,unsigned int flags);
```

~~零拷贝内存虽然不需要显式的传递到设备上，但是设备还不能通过 pHost 直接访问对应的内存地址，设备需要访问主机上的零拷贝内存，需要先获得另一个地址，这个地址帮助设备访问到主机对应的内存：~~

```c
// 已弃用
cudaError_t cudaHostGetDevicePointer(void ** pDevice,void * pHost,unsigned flags);
```

_有了 UVA 后，零拷贝内存的地址可以直接访问。_

设备访问零拷贝内存时，每次读写都要经过 PCIe，因此零拷贝内存效率极低。

#### 统一虚拟寻址

计算能力为 2.0 及以上版本的设备支持一种特殊的寻址方式，称为统一虚拟寻址（UVA）。有了 UVA，主机内存和设备内存可以共享同一个虚拟地址空间。

#### 统一内存寻址

在 CUDA 6.0 中，引入了“统一内存寻址”这一新特性，它用于简化 CUDA 编程模型中的内存管理。统一内存中创建了一个托管内存池，内存池中已分配的空间可以用相同的内存地址（即指针）在 CPU 和 GPU 上进行访问。

![uva](img/UVA.png)

托管内存可以被静态分配也可以被动态分配。可以通过添加`__managed__`注释，静态声明一个设备变量作为托管变量。但这个操作只能在文件范围和全局范围内进行。该变量可以从主机或设备代码中直接被引用：

```c
__device__ __managed__ int y;
```

还可以动态分配托管内存：

```c
// 分配size字节的托管内存，并用devPtr返回一个指针
cudaError_t cudaMallocManaged(void ** devPtr, size_t size, unsigned int flags=0);
```

使用托管内存的程序行为与使用未托管内存的程序副本行为在功能上是一致的。但是，使用托管内存的程序可以利用自动数据传输和重复指针消除功能。

### 内存访问模式

#### 对齐与合并访问

核函数运行时，SM 从全局内存（DRAM）中读取数据，只有两种粒度：32 字节或 128 字节。CUDA 是支持通过编译指令停用一级缓存的，如果启用一级缓存，那么每次从 DRAM 上加载数据的粒度是 128 字节；如果不使用一级缓存，只是用二级缓存，那么粒度是 32 字节。

内存事务：从内核函数发起请求，到硬件响应返回数据的过程。

一个内存事务的首个访问地址是缓存粒度（32 或 128 字节）的偶数倍，被称为**对齐内存访问**，非对齐的内存访问会造成带宽浪费。

当一个线程束内的线程访问的内存都在一个内存块里的时候，被称为**合并访问**。

为了最大化全局内存访问的效率，应尽量将线程束访问内存组织成对齐合并的方式。

#### 全局内存读写

![wr](img/memwr.png)

当 SM 请求全局数据时，如果启用 L1 Cache，读取粒度为 128 字节：

1. 访问一级缓存，若缺失；
2. 访问二级缓存，若缺失；
3. 访问全局内存/统一内存。

如果关闭 L1 Cache，读取粒度为 32 字节：

1. 访问二级缓存，若缺失；
2. 访问全局内存/统一内存。

$$
\text{全局加载效率} = \frac{\text{请求的全局内存加载吞吐量}}{\text{所需的全局内存加载吞吐量}}
$$

内存的写入相对简单很多，发送到设备前，只经过二级缓存，存储操作在 32 个字节的粒度上执行。

#### 结构体数组与数组结构体

数组结构体（AoS）就是一个数组，每个元素都是一个结构体，而结构体数组（SoA）就是结构体中的成员是数组：

```c
// AoS
struct A a[N];
// SoA
struct A{
    int a[N];
    int b[N]
};
```

并行编程范式，尤其是 SIMD（单指令多数据）对 SoA 更友好。CUDA 中普遍倾向于细粒度的 SoA，而不是粗粒度的 AoS，因为这种内存访问可以有效地合并。

#### 性能调整

优化设备内存带宽利用率有两个目标：

1. 对齐合并内存访问，以减少带宽的浪费；
2. 足够的并发内存操作，以隐藏内存延迟。

实现并发内存访问量最大化是通过以下方式得到的：

1. 增加每个线程中执行独立内存操作的数量；
2. 对核函数启动的执行配置进行试验，已充分体现每个 SM 的并行性。

### 核函数可达到的带宽

#### 内存带宽

**理论带宽**就是硬件设计的绝对最大值，硬件限制了这个最大值为多少；**有效带宽**是核函数实际达到的带宽，是测量带宽，可以用下面公式计算:

$$
\text{有效带宽} = \frac{(\text{读字节数} + \text{写字节数}) \times 10^{-9}}{\text{运行时间}}
$$

## 第 5 章 共享内存和常量内存

## 第 6 章 流和并发

## 第 7 章 调整指令级原语

## 第 8 章 GPU 加速库和 OpenACC

## 第 9 章 多 GPU 编程

## 第 10 章 程序实现的注意事项

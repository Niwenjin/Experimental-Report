# ROC-RK3588S-PC 开发板

## Linux 开发

安装交叉编译环境，下载源码（rootfs, kernel, u-boot, recovery），编译 Linux 固件，见[编译 Linux 固件](https://wiki.t-firefly.com/zh_CN/ROC-RK3588S-PC/linux_compile.html)。

使用 USB 连接，将固件烧录到开发板，见[使用 USB 线缆升级固件](https://wiki.t-firefly.com/zh_CN/ROC-RK3588S-PC/upgrade_firmware.html)。

Linux 手册，见[Firefly Linux 开发指南](https://wiki.t-firefly.com/zh_CN/Firefly-Linux-Guide/index.html)。

## 调试

### ADB 连接

Ubuntu 安装 adb：

```bash
sudo apt install adb
# 如果找不到 adb 包，使用 android-tools-adb
# sudo apt install android-tools-adb
```

显示版本信息：

```bash
adb version
```

查看当前连接的设备：

```bash
adb devices
```

登录设备 shell：

```bash
adb shell
adb -s <设备号> shell  # 当连接了多个设备，指定一个设备号进行连接
# exit
# exit退出当前连接的shell
```

文件操作指令：

```bash
# 上传文件到设备
adb push <本地路径> <设备路径>
# 下载文件到本地
adb pull <设备路径> <本地路径>
```

### SSH 连接

开发板连接局域网。

通过 ADB 获取开发板的 IP 地址：

```bash
$ ifconfig
...
inet 192.168.112.243
...
```

SSH 连接到开发板：

```
ip: 192.168.112.243
用户: firefly
密码: firefly
```

### 串口调试

RK3588s-pc 的串口针脚向下，定义依次为：

| RX7  | TX7 | ADC4 | 1V8 | 3V3 | 5V  | LOUT | GND | DM4 | DM3 |
| ---- | --- | ---- | --- | --- | --- | ---- | --- | --- | --- |
| G3C6 | CS  | CLK  | SD0 | SD1 | GND | ROUT | GND | DP4 | DP3 |

连接串口线，查看串口设备：

```bash
$ ls /dev/ttyS*
/dev/ttyS7
```

或者使用 USB 转 ttl 连接设备（需要安装 CH341 驱动）：

```bash
$ ls /dev/ttyUSB*
/dev/ttyUSB0
```

## 模型转换与部署

RK3588 内置 NPU 模块，使用的模型类型是 RKNN，模型文件后缀名为`.rknn`。

### RKNN 模型

可以使用 RKNN SDK 编写和构建 RKNN 模型，直接运行在 RK3588 平台上。

### 非 RKNN 模型

对于 Caffe、Pytorch、TensorFlow 等其他模型，需要先进行模型转换，才可以在 RK3588 平台运行。可以使用 RKNN-Toolkit2 工具将模型转换成 RKNN 格式。

RKNN-Toolkit2 适用系统 Ubuntu18.04(x64)(Python3.6)和 Ubuntu20.04(x64)(Python3.8)，详细环境依赖见文档[NPU 使用](https://wiki.t-firefly.com/zh_CN/ROC-RK3588S-PC/usage_npu.html)。

执行`convert.py`将onxx模型转换为krnn模型，转换过程：

1. RKNN对象创建和配置；
2. 调用`rknn.load_onnx()`加载ONNX模型；
3. 调用`rknn.build()`构建RKNN模型；
4. 调用`rknn.export_rknn()`导出RKNN模型；
5. 资源释放。

执行脚本`./build-linux.sh`，调用交叉编译器将`.rknn`模型和C++文件编译为可执行程序:

```sh
./build-linux.sh -t <target> -a <arch> -d <build_demo_name> [-b <build_type>] [-m]
    -t : target (rk356x/rk3588/rk3576/rv1106/rk1808/rv1126)
    -a : arch (aarch64/armhf)
    -d : demo name
    -b : build_type(Debug/Release)
    -m : enable address sanitizer, build_type need set to Debug
Note: 'rk356x' represents rk3562/rk3566/rk3568, 'rv1106' represents rv1103/rv1106, 'rv1126' represents rv1109/rv1126

# 以编译64位Linux RK3588的yolov8 demo为例:
./build-linux.sh -t rk3588 -a aarch64 -d yolov8
```

程序主要实现以下功能：

1. 图像加载和预处理；
2. 模型初始化；
3. 推理；
4. 输出结果。

将目录拷贝到开发板中，运行可执行文件：

```sh
./rknn_yolov8_demo <model_path> <image_path>
```

### rknn模型部署

调用RKNN模型进行预测的主要步骤如下：

1. 初始化RKNN上下文变量`rknn_app_ctx`；
2. 使用`rknn_init()`函数加载RKNN模型文件；
3. 使用`rknn_inputs_set()`函数设置模型的输入数据；
4. 调用`rknn_run()`函数执行模型推理；
5. 使用`rknn_outputs_get()`函数获取模型的推理输出结果；
6. 调用`rknn_destroy()`销毁模型上下文。

## 视频流的拉取和预处理

创建一个视频流类的实例，在后台启动一个线程调用ffmpeg拉取视频流到管道中，主线程不断从管道读取视频帧。当其他控制代码需要获取最新图片时，调用接口`get_image()`获取图片，将调用预处理函数对图像进行畸变还原和裁剪，并返回一个处理完成图像的clone。

```cpp
struct Frame
{
    cv::Mat data;
    bool is_processed;
};

class VideoStream
{
public:
    VideoStream(const std::string &stream_url) : stream_url(stream_url)
    {
        fisheye_init();
    }

    ~VideoStream()
    {
        stop_stream();
    }

    void start_stream();

    cv::Mat get_image();

    void stop_stream();

private:
    std::string stream_url;

    std::thread stream_thread;

    std::mutex frame_mutex;
    struct Frame frame;

    void run_stream();
    std::atomic<bool> is_running(false);

    // 矫正映射
    cv::Mat map1, map2;
    void preprocess(cv::Mat &mat);
    void fisheye_init();
};
```

拉流相关接口实现如下：

```cpp
void VideoStream::start_stream()
{
    is_running.store(true, std::memory_order_relaxed);
    stream_thread = std::thread(&VideoStream::run_stream, this);
}

cv::Mat VideoStream::get_image()
{
    try
    {
        if (frame.data.empty())
        {
            throw std::runtime_error("Frame data is empty");
        }

        std::lock_guard<std::mutex> lock(frame_mutex);

        // 预处理图像
        if (!frame.is_processed)
        {
            preprocess(frame.data);
            frame.is_processed = true;
        }

        return frame.data.clone();
    }
    catch (const std::exception &e)
    {
        std::cerr << "Exception caught in get_image: " << e.what() << std::endl;
        return cv::Mat();
    }
}

void VideoStream::stop_stream()
{
    is_running.store(false, std::memory_order_relaxed);
    if (stream_thread.joinable())
    {
        stream_thread.join();
    }
}

void VideoStream::run_stream()
{
    // ffmpeg命令
    std::string command = "ffmpeg -i " + stream_url
                          + " -f image2pipe -pix_fmt bgr24 -r 10.0 -vcodec rawvideo -";
    FILE *pipe = popen(command.c_str(), "r");

    if (!pipe)
    {
        std::cerr << "Could not start ffmpeg process\n";
        return;
    }

    const int width = 1280;
    const int height = 720;
    const int channels = 3;
    const int frame_size = width * height * channels;
    std::vector<unsigned char> buffer(frame_size);

    while (is_running.load(std::memory_order_relaxed))
    {
        // 从管道读取帧
        size_t read_bytes = fread(buffer.data(), 1, frame_size, pipe);
        if (read_bytes != frame_size)
        {
            std::cerr << "Failed to read frame from ffmpeg\n";
            break;
        }

        cv::Mat img(height, width, CV_8UC3, buffer.data());

        {
            std::lock_guard<std::mutex> lock(frame_mutex);
            frame.data = img.clone();
            frame.is_processed = false;
        }
    }
    std::cout << "stream stop running." << std::endl;
    pclose(pipe);
}
```

图像预处理接口实现如下：

```cpp
void VideoStream::preprocess(cv::Mat &mat)
{
    // 使用鱼眼模型进行畸变校正
    cv::Mat undistorted_img;
    cv::remap(mat, undistorted_img, map1, map2, cv::INTER_LINEAR);

    // 裁剪图像为 640x640
    int width = 640;
    int height = 640;

    int x_start = (mat.cols - width) / 2;
    int y_start = (mat.rows - height) / 2;
    x_start = std::max(0, x_start);
    y_start = std::max(0, y_start);

    cv::Rect cropRegion(x_start, y_start, width, height);
    cv::Mat cropped_img = undistorted_img(cropRegion);

    cropped_img.copyTo(mat);
}

void VideoStream::fisheye_init()
{
    // A2 mini 参数
    // 内参矩阵
    const cv::Mat K =
        (cv::Mat_<double>(3, 3) << 453.45595575359556, 0.0, 674.8978536877463,
         0.0, 454.5785884236175, 358.6917102226701, 0.0, 0.0, 1.0);

    // 畸变系数
    const cv::Mat D = (cv::Mat_<double>(1, 4) << 0.0, 0.0, 0.0, 0.0);

    cv::Size imageSize(1280, 720);
    cv::fisheye::initUndistortRectifyMap(
        K, D, cv::Mat::eye(3, 3, CV_64F), K, imageSize, CV_16SC2, map1, map2);
}
```

## 目标检测和OCR的结合

由于yolo对于小目标的类别判断效果不佳，因此采用预处理 + yolo + 图像后处理 + OCR的方式。主要流程如下：

1. 调用`get_image`获取经过预处理的图像，格式为`cv::Mat`；
2. 将图像输入yolo模型，获取到输出：目标框 + 类别 + 置信度；
3. 根据目标框裁剪出部分图像；
4. 使用边缘检测等方法获取目标外层的黑色矩形框，进行背景填充和旋转；
5. 将处理完的图像输入OCR模型，更新输出的类别。

图像后处理的实现如下：

```cpp
// 边缘填充并旋转
void extractTextWithBlackBackground(cv::Mat &mat)
{
    if (mat.empty() || mat.rows != mat.cols)
    {
        std::cerr << "Input image must be non-empty and square." << std::endl;
        return;
    }

    cv::Mat hsv;
    cv::cvtColor(mat, hsv, cv::COLOR_BGR2HSV);

    cv::Mat mask;
    cv::inRange(hsv, cv::Scalar(0, 0, 200), cv::Scalar(180, 30, 255), mask); // 白色范围

    // 收集所有非背景点的位置
    std::vector<cv::Point> points;
    for (int y = 0; y < mask.rows; ++y)
    {
        for (int x = 0; x < mask.cols; ++x)
        {
            if (mask.at<uchar>(y, x) != 0)
            {
                points.push_back(cv::Point(x, y));
            }
        }
    }

    // 没有检测到有效区域，直接返回
    if (points.empty())
    {
        std::cerr << "No significant area found. The output will be a black image." << std::endl;
        mat = cv::Mat::zeros(mat.size(), mat.type());
        return;
    }

    // 计算最小外接矩形
    cv::RotatedRect rotatedRect = cv::minAreaRect(points);
    float angle = rotatedRect.angle;
    if (rotatedRect.size.width < rotatedRect.size.height)
    {
        angle += 90;
    }

    // 创建黑色背景图像，大小与原图相同
    cv::Mat black_background = cv::Mat::zeros(mat.size(), mat.type());

    try
    {
        // 从原始图像中提取文字区域并复制到黑色背景图像的相同位置
        cv::Rect text_rect = cv::boundingRect(points);
        mat(text_rect).copyTo(black_background(text_rect));

        // 创建旋转矩阵
        cv::Point2f center(black_background.cols / 2.0, black_background.rows / 2.0);
        cv::Mat rot_mat = cv::getRotationMatrix2D(center, angle, 1.0);

        // 计算旋转后的图像大小
        int newSize = black_background.cols; // 因为图像是正方形的，使用边长
        cv::Rect bbox(0, 0, newSize, newSize);
        rot_mat.at<double>(0, 2) += bbox.width / 2.0 - center.x;
        rot_mat.at<double>(1, 2) += bbox.height / 2.0 - center.y;

        // 旋转图像
        cv::Mat rotated_image;
        cv::warpAffine(black_background, rotated_image, rot_mat, bbox.size(), cv::INTER_LINEAR, cv::BORDER_CONSTANT, cv::Scalar(0, 0, 0));

        // 更新原始图像为旋转后的图像
        mat = rotated_image;
    }
    catch (const cv::Exception &e)
    {
        std::cerr << "OpenCV exception caught: " << e.what() << std::endl;
    }
    catch (...)
    {
        std::cerr << "Unknown exception caught." << std::endl;
    }
}
```

完整的图像检测实现如下：

```cpp
std::vector<detect_target> yolo_detect_with_ocr(
    const char *yolo_model_path, const char *ocr_model_path, const cv::Mat mat,
    float yolo_threshold, float ocr_threshold)
{
    std::vector<detect_target> targets =
        yolo_detect(yolo_model_path, mat, yolo_threshold);
    if (targets.empty())
    {
        // printf("No target detected\n");
        return targets;
    }

    for (detect_target &target : targets)
    {
        // 测试
        std::cout << "x1: " << target.x1 << "\ny1: " << target.y1
                  << "\nx2: " << target.x2 << "\ny2: " << target.y2
                  << "\nclass_id: " << target.class_id << "\nprob: " << target.prob
                  << std::endl;

        // 裁剪正方形图像
        int width = std::max(target.x2 - target.x1, target.y2 - target.y1);
        cv::Rect target_rect(target.x1, target.y1, width, width);
        cv::Mat cropped_mat = mat(target_rect);
        // cv::imwrite("cropped_mat.png",cropped_mat);

        // 背景填充
        extractTextWithBlackBackground(cropped_mat);
        // cv::imwrite("filled_mat.png",cropped_mat);

        // 识别
        std::vector<ppocr_result> ocr_results =
            ppocr_rec_with_rotate(ocr_model_path, cropped_mat);
        ppocr_result best_ocr_result;
        float best_prob = 0;
        for (ppocr_result &res : ocr_results)
        {
            if (res.score > best_prob)
            {
                best_prob = res.score;
                best_ocr_result = res;
            }
        }
        if (best_prob < ocr_threshold)
        {
            target.class_id = 0;
            continue;
        }
        if (best_ocr_result.str[0] == '1')
        {
            target.class_id = 1;
            target.prob *= best_prob;
        }
        else if (best_ocr_result.str[0] == '2')
        {
            target.class_id = 2;
            target.prob *= best_prob;
        }
        else if (best_ocr_result.str[0] == '3')
        {
            target.class_id = 3;
            target.prob *= best_prob;
        }
        else
        {
            target.class_id = 0;
            target.prob *= best_prob;
        }
    }
    return targets;
}
```